{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306efd2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T10:49:32.452466Z",
     "start_time": "2026-02-03T10:49:09.636649Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e2b291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T10:50:27.665646Z",
     "start_time": "2026-02-03T10:50:27.645653Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = fr\"runs\\detect\\train4\\weights\\best.pt\"\n",
    "yaml_path = \"datasets/vaca/data.yaml\"\n",
    "image_path = r\"datasets\\vaca\\images\\val\\vj32_jpg.rf.26e063f5a917a9e05dedcb26ab7726d1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ef5c77",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-03T10:50:29.494213Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60864813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'cow'}\n"
     ]
    }
   ],
   "source": [
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e90b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'detect', 'mode': 'train', 'model': 'C:\\\\_projects\\\\dev\\\\smart_inventory\\\\yolo26n.pt', 'data': 'C:\\\\_projects\\\\dev\\\\smart_inventory\\\\datasets\\\\vaca\\\\data.yaml', 'epochs': 120, 'time': None, 'patience': 100, 'batch': 1, 'imgsz': 512, 'save': True, 'save_period': -1, 'cache': False, 'device': 'cpu', 'workers': 0, 'project': None, 'name': 'train4', 'exist_ok': False, 'pretrained': True, 'optimizer': 'auto', 'verbose': True, 'seed': 0, 'deterministic': True, 'single_cls': False, 'rect': False, 'cos_lr': False, 'close_mosaic': 10, 'resume': False, 'amp': True, 'fraction': 1.0, 'profile': False, 'freeze': None, 'multi_scale': 0.0, 'compile': False, 'overlap_mask': True, 'mask_ratio': 4, 'dropout': 0.0, 'val': True, 'split': 'val', 'save_json': False, 'conf': None, 'iou': 0.7, 'max_det': 300, 'half': False, 'dnn': False, 'plots': True, 'source': None, 'vid_stride': 1, 'stream_buffer': False, 'visualize': False, 'augment': False, 'agnostic_nms': False, 'classes': None, 'retina_masks': False, 'embed': None, 'show': False, 'save_frames': False, 'save_txt': False, 'save_conf': False, 'save_crop': False, 'show_labels': True, 'show_conf': True, 'show_boxes': True, 'line_width': None, 'format': 'torchscript', 'keras': False, 'optimize': False, 'int8': False, 'dynamic': False, 'simplify': True, 'opset': None, 'workspace': None, 'nms': False, 'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.0, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0, 'rle': 1.0, 'angle': 1.0, 'nbs': 64, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'copy_paste_mode': 'flip', 'auto_augment': 'randaugment', 'erasing': 0.4, 'cfg': None, 'tracker': 'botsort.yaml'}\n"
     ]
    }
   ],
   "source": [
    "print(model.ckpt['train_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8b599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.7  Python-3.12.0 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-1185G7 @ 3.00GHz)\n",
      "YOLO26n summary (fused): 122 layers, 2,375,031 parameters, 0 gradients, 5.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 565.8218.1 MB/s, size: 2599.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\_projects\\dev\\smart_inventory\\datasets\\vaca\\labels\\val.cache... 43 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 43/43  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 4.1s/it 12.2s.7ss\n",
      "                   all         43       8656       0.73      0.464      0.571      0.262\n",
      "Speed: 0.9ms preprocess, 96.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\_projects\\dev\\smart_inventory\\runs\\detect\\val13\u001b[0m\n",
      "\n",
      "--------------------------------------------------\n",
      "Validation Metrics:\n",
      "mAP50: 0.571\n",
      "mAP50-95: 0.262\n",
      "Precision: 0.73\n",
      "Recall: 0.464\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=yaml_path)\n",
    "print(\"\")\n",
    "print(50*\"-\")\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"mAP50:\", metrics.box.map50.round(3))\n",
    "print(\"mAP50-95:\", metrics.box.map.round(3))\n",
    "print(\"Precision:\", metrics.box.mp.round(3))\n",
    "print(\"Recall:\", metrics.box.mr.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b3c521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\_projects\\dev\\smart_inventory\\datasets\\vaca\\images\\val\\vj32_jpg.rf.26e063f5a917a9e05dedcb26ab7726d1.jpg: 288x512 99 cows, 147.6ms\n",
      "Speed: 2.2ms preprocess, 147.6ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 512)\n"
     ]
    }
   ],
   "source": [
    "results = model(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe94e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3059685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\_projects\\dev\\smart_inventory\\datasets\\vaca\\images\\val\\vj32_jpg.rf.26e063f5a917a9e05dedcb26ab7726d1.jpg: 288x512 99 cows, 158.2ms\n",
      "Speed: 1.6ms preprocess, 158.2ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Results saved to \u001b[1mC:\\_projects\\dev\\smart_inventory\\runs\\detect\\predict8\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'cow'}\n",
       " obb: None\n",
       " orig_img: array([[[ 82, 131, 157],\n",
       "         [ 83, 132, 158],\n",
       "         [ 52, 101, 127],\n",
       "         ...,\n",
       "         [  0,  26,  42],\n",
       "         [  4,  27,  42],\n",
       "         [ 11,  34,  49]],\n",
       " \n",
       "        [[ 67, 116, 142],\n",
       "         [ 58, 107, 133],\n",
       "         [ 42,  91, 117],\n",
       "         ...,\n",
       "         [  0,  20,  36],\n",
       "         [  0,  20,  35],\n",
       "         [ 11,  34,  49]],\n",
       " \n",
       "        [[ 75, 124, 150],\n",
       "         [ 43,  92, 118],\n",
       "         [ 41,  90, 116],\n",
       "         ...,\n",
       "         [  5,  30,  46],\n",
       "         [  0,  16,  32],\n",
       "         [  6,  26,  43]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 75, 121, 145],\n",
       "         [ 75, 121, 145],\n",
       "         [ 84, 130, 154],\n",
       "         ...,\n",
       "         [ 54, 109, 136],\n",
       "         [ 25,  78, 105],\n",
       "         [  4,  57,  84]],\n",
       " \n",
       "        [[ 91, 137, 161],\n",
       "         [ 95, 141, 165],\n",
       "         [ 82, 128, 152],\n",
       "         ...,\n",
       "         [ 59, 112, 139],\n",
       "         [ 41,  94, 121],\n",
       "         [  4,  57,  84]],\n",
       " \n",
       "        [[ 91, 137, 161],\n",
       "         [ 95, 141, 165],\n",
       "         [ 82, 128, 152],\n",
       "         ...,\n",
       "         [ 71, 124, 151],\n",
       "         [ 69, 122, 149],\n",
       "         [ 44,  97, 124]]], shape=(2250, 4000, 3), dtype=uint8)\n",
       " orig_shape: (2250, 4000)\n",
       " path: 'c:\\\\_projects\\\\dev\\\\smart_inventory\\\\datasets\\\\vaca\\\\images\\\\val\\\\vj32_jpg.rf.26e063f5a917a9e05dedcb26ab7726d1.jpg'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\_projects\\\\dev\\\\smart_inventory\\\\runs\\\\detect\\\\predict8'\n",
       " speed: {'preprocess': 1.5929999644868076, 'inference': 158.2108999718912, 'postprocess': 0.6113999988883734}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    source=image_path,\n",
    "    save=True,\n",
    "    show_labels=False,   # üëà tira o texto\n",
    "    show_conf=False,     # üëà tira o score (opcional)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b5814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
